# ðŸ’³ Finance Club Project - Credit Default Prediction

> **Goal**: Predict credit card defaults with a focus on **Recall** (capturing risk) using an F2-Score optimized XGBoost pipeline.

> [!TIP]
> *   **Problem Statement**: [Finclub Summer Project 2 (2025).pdf](Finclub%20Summer%20Project%202%20(2025).pdf)
> *   **Final Report**: [Finance_club_ML_project_Report.pdf](Finance_club_ML_project_Report.pdf)
> *   **Experimental Notebook**: [Finance_club_project (2).ipynb](notebooks/Finance_club_project%20(2).ipynb)

---

## ðŸ“Š Pipeline Architecture

```mermaid
graph TD
    %% Nodes
    A[ðŸ“‚ Raw CSV Data] --> B(ðŸ› ï¸ Feature Engineering)
    B -->|AVG_Bill_amt, Ratios| C{âš™ï¸ Preprocessing}
    
    C -->|Train Split| D[âš–ï¸ SMOTE Resampling]
    C -->|Test Split| E[ðŸ“ Scaling]
    
    D --> F[ðŸš€ XGBoost Training]
    F --> G[ðŸŽ›ï¸ Threshold Tuning]
    E --> G
    
    G -->|Maximize F2| H[ðŸ“ˆ Final Evaluation]
    H --> I[ðŸ“„ Results & Plots]
    
    %% Styling
    style A fill:#f9f,stroke:#333,stroke-width:2px
    style F fill:#ff9,stroke:#333,stroke-width:2px
    style H fill:#9f9,stroke:#333,stroke-width:2px
```

---

## ðŸš€ Key Features

| Feature | Description |
| :--- | :--- |
| **Modular Design** | Separation of `Data`, `Features`, and `Models` for production readiness. |
| **F2-Score Focus** | Optimized specifically to catch defaulters (High Recall) over simple accuracy. |
| **Smart Tuning** | Threshold optimization loop (`0.01` to `1.0`) to find the perfect cut-off. |
| **Visual Artifacts** | Automatically generates **ROC**, **PR Curves**, and **Confusion Matrices** per run. |

---

## ðŸ“‚ Project Structure

```text
FinanceClub_Project/
â”œâ”€â”€ ðŸ“„ main.py                  # ðŸš€ Pipeline Entry Point
â”œâ”€â”€ ðŸ“‚ config/
â”‚   â””â”€â”€ config.yaml             # âš™ï¸ Hyperparameters & Paths
â”œâ”€â”€ ðŸ“‚ data/
â”‚   â””â”€â”€ raw/                    # ðŸ“¥ Input: train_dataset_final1.csv
â”œâ”€â”€ ðŸ“‚ logs/                    # ðŸ“ Execution Logs
â”œâ”€â”€ ðŸ“‚ results/                 # ðŸ“Š Outputs (Metrics, Plots, Predictions)
â”‚   â””â”€â”€ run_20231228_.../       #    Timestamped Artifacts
â”œâ”€â”€ ðŸ“‚ src/
â”‚   â”œâ”€â”€ ðŸ› ï¸ features/            #    Engineering, Preprocessing, Resampling
â”‚   â”œâ”€â”€ ðŸ¤– models/              #    XGBoost Trainer, Tuner
â”‚   â””â”€â”€ ðŸ”Œ data/                #    Loaders
â””â”€â”€ ðŸ“¦ requirements.txt         #    Dependencies
```

---

## âš¡ Quick Start

### 1. Install Dependencies
```bash
pip install -r requirements.txt
```

### 2. Run Pipeline
```bash
python main.py
```

### 3. View Results
Checking `results/` will show:
*   `metrics.json`: Accuracy, Precision, Recall, F2, AUC.
*   `roc_curve.png`: Model discrimination performance.
*   `feature_importance.png`: What drives the predictions?

---

## ðŸ§  Model Details

> [!NOTE]
> The model uses **XGBoost** with a heavily weighted positive class (`scale_pos_weight: ~6.38`) to address the 80/20 class imbalance.

*   **Algorithm**: XGBoost Classifier
*   **Best Params**: `n_estimators: 300`, `max_depth: 7`, `learning_rate: 0.05`
*   **Imbalance Strategy**: SMOTE (Synthetic Minority Over-sampling) on Training Data only.

---
*Generated for Finance Club Project Refactoring*
